# CSE 253 Final Project

clone this repo: https://github.com/tylin/coco-caption in the working project 
directory for metrics. The functionality in this repo is used in
"get_metrics" in attention_trainer.py 

TODO: 
- visualization of layers
- evaluation with metrics
- add attention LSTM model

- experiment with number of layers
- experiment with Flickr
- compare attention vs no-attention

How can we make our code different from just pulling github repos? 
- Different preprocessing transforms
- Different CNN architectures?
- Different Hyperparams / num layers of LSTM
  
- Different Attention models if we can even get attention working in the first place
    > Soft vs hard
    > Other options such as text-guided, visual guided
